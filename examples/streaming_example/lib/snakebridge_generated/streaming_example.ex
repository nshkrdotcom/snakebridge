# Generated by SnakeBridge v0.8.2 - DO NOT EDIT MANUALLY
# Regenerate with: mix compile
# Library: streaming_example stdlib

defmodule Streaming do
  @moduledoc """
  SnakeBridge bindings for `streaming_example`.

  ## Runtime Options

  All functions accept a `__runtime__` option for controlling execution behavior:

      Elixir.Streaming.some_function(args, __runtime__: [timeout: 120_000])

  ### Supported runtime options

  - `:timeout` - Call timeout in milliseconds (default: 120,000ms / 2 minutes)
  - `:timeout_profile` - Use a named profile (`:default`, `:ml_inference`, `:batch_job`, `:streaming`)
  - `:stream_timeout` - Timeout for streaming operations (default: 1,800,000ms / 30 minutes)
  - `:session_id` - Override the session ID for this call
  - `:pool_name` - Target a specific Snakepit pool (multi-pool setups)
  - `:affinity` - Override session affinity (`:hint`, `:strict_queue`, `:strict_fail_fast`)

  ### Timeout Profiles

  - `:default` - 2 minute timeout for regular calls
  - `:ml_inference` - 10 minute timeout for ML/LLM workloads
  - `:batch_job` - Unlimited timeout for long-running jobs
  - `:streaming` - 2 minute timeout, 30 minute stream_timeout

  ### Example with timeout override

      # For a long-running ML inference call
      Elixir.Streaming.predict(data, __runtime__: [timeout_profile: :ml_inference])

      # Or explicit timeout
      Elixir.Streaming.predict(data, __runtime__: [timeout: 600_000])

      # Route to a pool and enforce strict affinity
      Elixir.Streaming.predict(data, __runtime__: [pool_name: :strict_pool, affinity: :strict_queue])

  See `SnakeBridge.Defaults` for global timeout configuration.
  """

  def __snakebridge_python_name__, do: "streaming_example"
  def __snakebridge_library__, do: "streaming_example"

  @doc """
  Generate either a full response or a stream of chunks.

  Parameters:
  - `prompt` (term())
  - `stream` (term() default: False)
  - `count` (term() default: 3)
  - `delay` (term() default: 0.01)

  Returns:
  - `term()`
  """
  @spec generate(term()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  @spec generate(term(), keyword()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  @spec generate(term(), term()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  @spec generate(term(), term(), keyword()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  @spec generate(term(), term(), term()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  @spec generate(term(), term(), term(), keyword()) ::
          {:ok, term()} | {:error, Snakepit.Error.t()}
  @spec generate(term(), term(), term(), term()) :: {:ok, term()} | {:error, Snakepit.Error.t()}
  @spec generate(term(), term(), term(), term(), keyword()) ::
          {:ok, term()} | {:error, Snakepit.Error.t()}
  def generate(prompt) do
    SnakeBridge.Runtime.call(__MODULE__, :generate, [prompt], [])
  end

  def generate(prompt, opts)
      when is_list(opts) and
             (opts == [] or
                (is_tuple(hd(opts)) and tuple_size(hd(opts)) == 2 and is_atom(elem(hd(opts), 0)))) do
    SnakeBridge.Runtime.call(__MODULE__, :generate, [prompt], opts)
  end

  def generate(prompt, stream) do
    SnakeBridge.Runtime.call(__MODULE__, :generate, [prompt, stream], [])
  end

  def generate(prompt, stream, opts)
      when is_list(opts) and
             (opts == [] or
                (is_tuple(hd(opts)) and tuple_size(hd(opts)) == 2 and is_atom(elem(hd(opts), 0)))) do
    SnakeBridge.Runtime.call(__MODULE__, :generate, [prompt, stream], opts)
  end

  def generate(prompt, stream, count) do
    SnakeBridge.Runtime.call(__MODULE__, :generate, [prompt, stream, count], [])
  end

  def generate(prompt, stream, count, opts)
      when is_list(opts) and
             (opts == [] or
                (is_tuple(hd(opts)) and tuple_size(hd(opts)) == 2 and is_atom(elem(hd(opts), 0)))) do
    SnakeBridge.Runtime.call(__MODULE__, :generate, [prompt, stream, count], opts)
  end

  def generate(prompt, stream, count, delay) do
    SnakeBridge.Runtime.call(__MODULE__, :generate, [prompt, stream, count, delay], [])
  end

  def generate(prompt, stream, count, delay, opts)
      when is_list(opts) and
             (opts == [] or
                (is_tuple(hd(opts)) and tuple_size(hd(opts)) == 2 and is_atom(elem(hd(opts), 0)))) do
    SnakeBridge.Runtime.call(__MODULE__, :generate, [prompt, stream, count, delay], opts)
  end

  @doc """
  Streaming variant of `generate/3`.

  The callback receives chunks as they arrive.
  """
  @spec generate_stream(term(), list(term()), keyword(), (term() -> any())) ::
          :ok | {:error, Snakepit.Error.t()}
  def generate_stream(prompt, args, opts \\ [], callback) when is_function(callback, 1) do
    {args, opts} = SnakeBridge.Runtime.normalize_args_opts(args, opts)
    SnakeBridge.Runtime.stream(__MODULE__, :generate, [prompt] ++ List.wrap(args), opts, callback)
  end

  @doc false
  def __functions__ do
    [
      {:generate, 1, __MODULE__, "Generate either a full response or a stream of chunks."}
    ]
  end

  @doc false
  def __classes__ do
    []
  end

  @doc false
  def __search__(query) do
    SnakeBridge.Docs.search(__MODULE__, query)
  end

  @doc false
  def doc(function) do
    SnakeBridge.Docs.get(__MODULE__, function)
  end
end
